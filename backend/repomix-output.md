This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-25T19:20:13.050Z

# File Summary

## Purpose
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Info

# Directory Structure
```
apps/
  engine/
    views.py
docker/
  sandbox/
    sandbox_server.py
```

# Files

## File: apps/engine/views.py
```python
from django.shortcuts import render
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status, permissions
from .tasks import execute_code, get_execution_result
from celery.result import AsyncResult
import logging
from redis.exceptions import ConnectionError
import redis
from celery.app.control import Control
from config.celery import app as celery_app

logger = logging.getLogger(__name__)

class ServiceStatus:
    @staticmethod
    def check_redis():
        try:
            r = redis.Redis(
                host='redis',
                port=6379,
                db=0,
                socket_connect_timeout=2,
                socket_timeout=2
            )
            r.ping()
            return True, "Connected"
        except (redis.ConnectionError, ConnectionError) as e:
            return False, str(e)

    @staticmethod
    def check_celery():
        try:
            control = Control(celery_app)
            workers = control.ping(timeout=1)
            if not workers:
                return False, "No workers available"
            return True, "Workers active"
        except Exception as e:
            return False, str(e)

class HealthCheckView(APIView):
    authentication_classes = []
    permission_classes = [permissions.AllowAny]

    def get(self, request):
        redis_status, redis_message = ServiceStatus.check_redis()
        celery_status, celery_message = ServiceStatus.check_celery()

        status_info = {
            'redis': {
                'status': 'healthy' if redis_status else 'unhealthy',
                'message': redis_message
            },
            'celery': {
                'status': 'healthy' if celery_status else 'unhealthy',
                'message': celery_message
            }
        }

        overall_status = status.HTTP_200_OK if (redis_status and celery_status) else status.HTTP_503_SERVICE_UNAVAILABLE
        return Response(status_info, status=overall_status)

class TaskResultView(APIView):
    authentication_classes = []
    permission_classes = [permissions.AllowAny]
    
    def get(self, request, task_id):
        try:
            # First check if the task is still in Celery
            celery_result = AsyncResult(task_id)
            
            if celery_result.ready():
                # If Celery task is done, check Redis for actual execution result
                result_task = get_execution_result.delay(task_id)
                execution_result = result_task.get(timeout=5)  # Short timeout as this should be quick
                
                if execution_result['status'] == 'completed':
                    return Response(execution_result)
                elif execution_result['status'] == 'error':
                    return Response({
                        'error': execution_result['error']
                    }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
                
            return Response({
                'status': 'pending',
                'message': 'Task is still processing'
            })
            
        except Exception as e:
            logger.error(f"Error checking task status: {str(e)}")
            return Response({
                'error': f"Error checking task status: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class CodeExecutionView(APIView):
    authentication_classes = []
    permission_classes = [permissions.AllowAny]
    
    def check_services(self):
        redis_status, redis_message = ServiceStatus.check_redis()
        celery_status, celery_message = ServiceStatus.check_celery()
        
        if not redis_status:
            return False, f"Redis service unavailable: {redis_message}"
        if not celery_status:
            return False, f"Celery service unavailable: {celery_message}"
        return True, "Services operational"
    
    def post(self, request):
        services_ok, message = self.check_services()
        if not services_ok:
            logger.error(message)
            return Response({
                'error': message
            }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
            
        code = request.data.get('code')
        
        if not code:
            return Response(
                {'error': 'No code provided'},
                status=status.HTTP_400_BAD_REQUEST
            )
            
        try:
            # Execute code asynchronously
            task = execute_code.delay(code)
            
            return Response({
                'task_id': task.id,
                'status': 'pending',
                'message': 'Code execution task has been queued',
                'status_url': f'/engine/task/{task.id}/'
            }, status=status.HTTP_202_ACCEPTED)
            
        except Exception as e:
            logger.error(f"Unexpected error in code execution: {str(e)}")
            return Response({
                'error': 'An unexpected error occurred'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
```

## File: docker/sandbox/sandbox_server.py
```python
import redis
import subprocess
import os
import tempfile
import json
import psutil
import logging
from contextlib import contextmanager
import signal
import time
import uuid

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Constants
MAX_EXECUTION_TIME = 30  # seconds
MAX_MEMORY = 512 * 1024 * 1024  # 512MB in bytes
REDIS_QUEUE_KEY = 'code_execution_queue'
REDIS_RESULT_KEY_PREFIX = 'code_result:'

class TimeoutException(Exception):
    pass

@contextmanager
def time_limit(seconds):
    def signal_handler(signum, frame):
        raise TimeoutException("Code execution timed out")
    
    signal.signal(signal.SIGALRM, signal_handler)
    signal.alarm(seconds)
    
    try:
        yield
    finally:
        signal.alarm(0)

def monitor_process(proc):
    """Monitor process resources"""
    try:
        process = psutil.Process(proc.pid)
        while proc.poll() is None:
            memory_info = process.memory_info()
            if memory_info.rss > MAX_MEMORY:
                proc.kill()
                return False, "Memory limit exceeded"
            time.sleep(0.1)
        return True, None
    except psutil.NoSuchProcess:
        return True, None
    except Exception as e:
        return False, str(e)

def execute_code(code, task_id):
    """Execute code in a sandboxed environment"""
    try:
        # Create a temporary file to store the code
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            temp_file = f.name
            logger.info(f"printing code from execute code {code}")
        try:
            with time_limit(MAX_EXECUTION_TIME):
                # Execute the code in a separate process
                proc = subprocess.Popen(
                    ['python', temp_file],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    preexec_fn=os.setsid
                )

                # Monitor process resources
                success, error_msg = monitor_process(proc)
                if not success:
                    os.killpg(os.getpgid(proc.pid), signal.SIGKILL)
                    return {
                        'success': False,
                        'error': error_msg,
                        'task_id': task_id
                    }

                stdout, stderr = proc.communicate()
                
                return {
                    'success': proc.returncode == 0,
                    'result': stdout.decode('utf-8'),
                    'error': stderr.decode('utf-8') if proc.returncode != 0 else None,
                    'task_id': task_id
                }

        except TimeoutException:
            return {
                'success': False,
                'error': 'Code execution timed out',
                'task_id': task_id
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'task_id': task_id
            }
        finally:

            try:
                os.unlink(temp_file)
            except:
                pass

    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'task_id': task_id
        }

def main():
    # Connect to Redis
    redis_client = redis.Redis(
        host='redis',  # Docker service name
        port=6379,
        db=0,
        socket_timeout=5,
        retry_on_timeout=True
    )

    logger.info("Starting sandbox worker...")
    
    while True:
        try:
            task = redis_client.brpop(REDIS_QUEUE_KEY, timeout=1)
            
            if task is None:
                continue
                
            task_data = json.loads(task[1])
            code = task_data['code']
            task_id = task_data['task_id']
            
            logger.info(f"Executing task {task_id}")
            
            result = execute_code(code, task_id)
            logger.info(f"printing the result {result}")
            result_key = f"{REDIS_RESULT_KEY_PREFIX}{task_id}"
            redis_client.setex(
                result_key,
                3600,
                json.dumps(result)
            )
            
            logger.info(f"Task {task_id} completed")
            
        except redis.RedisError as e:
            logger.error(f"Redis error: {str(e)}")
            time.sleep(1)  # Wait before retry
        except Exception as e:
            logger.error(f"Unexpected error: {str(e)}")
            time.sleep(1)  # Wait before retry

if __name__ == '__main__':
    main()
```
